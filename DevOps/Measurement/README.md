# Measurement

## Why is it Important

There are many frameworks and methodologies that aim to improve the way we build software. This chapter discusses what works using a scientific approach, defining what “good” means in the context of software delivery. Unlike manufacturing, where inventory is tangible, software is largely invisible, making it difficult to measure performance effectively.

Previous attempts to measure software productivity have often fallen short due to two main drawbacks:

- **Focusing on outputs instead of outcomes:** Metrics like lines of code, velocity, or utilization emphasize activity rather than value delivered.  
- **Focusing on individuals rather than teams:** Software is delivered collaboratively, so measuring individual contributions can be misleading.

Effective measurement is essential because **delivery performance strongly impacts organizational outcomes**, including:

- Profitability  
- Market share  
- Productivity  

Studies show that high-performing organizations are **twice as likely** to exceed these goals compared to low performers. High performers also excel in non-commercial outcomes, such as delivering customer or stakeholder satisfaction reliably, securely, and quickly.

Small batch work is particularly important because it allows teams to gather user feedback rapidly, using techniques such as A/B testing.  

Finally, the importance of software delivery performance argues for keeping **strategic software development in-house**, rather than outsourcing it. In contrast, non-strategic software (e.g., office productivity or payroll systems) is often better sourced via SaaS models.

## What is DORA Metrics

The **DORA (DevOps Research & Assessment) Metrics** are a set of four key measurements that have been empirically shown to correlate strongly with software delivery performance and organizational outcomes:

1. **Lead Time:** The time it takes from code being committed to code successfully running in production.  
2. **Deployment Frequency:** How often an organization successfully releases to production.  
3. **Mean Time to Recover (MTTR):** The average time it takes to restore service after an incident.  
4. **Change Failure Percentage:** The proportion of changes that result in degraded service or require remediation.

These metrics focus on **outcomes rather than outputs**, providing leaders with actionable insights that can drive continuous improvement across teams and products.

## Key Enablers

The ability to improve measurement and delivery performance depends on several organizational and technical factors:

- **Working in small batches:** Enables faster feedback loops and quicker validation of assumptions.  
- **Building strategic software capabilities internally:** Keeps critical knowledge and expertise at the core of the business.  
- **Learning-oriented culture:** Measurement is most powerful in organizations where it is used to **learn and improve**, not to control or punish.  
  - In bureaucratic or fear-driven cultures, metrics may be manipulated or hidden, leading to unreliable data.  
- **Scientific, data-driven approach:** Focus on empirically validated metrics rather than traditional proxies like lines of code or individual productivity.  

When these enablers are present, measurement becomes a **driver of high performance**, aligning teams with business outcomes and supporting continuous improvement.
